{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MH4518 Group Project\n",
    "\n",
    "Product: https://derivative.credit-suisse.com/ch/ch/en/detail/drop-back-certificate-s-p-500/CH1199361879/119936187\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initial Set-up\n",
    "\n",
    "<ol>\n",
    "<li> Set directories\n",
    "<li> Install dependencies\n",
    "<li> Import libraries\n",
    "</ol>\n",
    "\n",
    "NOTE: Ensure you are using the correct kernel to run the Jupyter Notebook with the correctly set root driectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# Set the root directory accordingly\n",
    "ROOT_DIR = \"/Users/dhruvchopra/Desktop/SimTech/MH4518\"\n",
    "os.chdir(ROOT_DIR)\n",
    "#sys.path.append(ROOT_DIR)\n",
    "\n",
    "# The data directory is set relative to root\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional libraries using pip\n",
    "#! pip install -r requirements.txt\n",
    "\n",
    "# Or if you have Conda installed (reccommended)\n",
    "# conda env create -f environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "from numba import jit, njit\n",
    "from nelson_siegel_svensson.calibrate import calibrate_ns_ols\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Suppresing the Deprecation Notices while using numba (reccommended)\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading Data\n",
    "\n",
    "The asset and product price data was collected and preprocessed using the scripts present in the `/data` directory.\n",
    "<li> Start date: 09-08-2022\n",
    "<li> End date: 09-11-2023\n",
    "<br>\n",
    "\n",
    "TODO: Update datasets (currently only till Oct 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load price data\n",
    "asset_prices = pd.read_csv(os.path.join(DATA_DIR, \"asset_price_1_year.csv\"))\n",
    "asset_prices[\"date\"] = pd.to_datetime(asset_prices[\"date\"])\n",
    "asset_prices = asset_prices.set_index(\"date\")\n",
    "\n",
    "product_prices = pd.read_csv(os.path.join(DATA_DIR, \"product_price_1_year.csv\"))\n",
    "product_prices[\"date\"] = pd.to_datetime(product_prices[\"date\"])\n",
    "product_prices = product_prices.set_index(\"date\")\n",
    "\n",
    "# Sanity check\n",
    "assert len(asset_prices) == len(product_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 13)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data on daily interest rate\n",
    "interest_rates = pd.read_csv(os.path.join(DATA_DIR, \"daily_treasury_rate_1_year.csv\"))\n",
    "interest_rates[\"date\"] = pd.to_datetime(interest_rates[\"date\"])\n",
    "interest_rates = interest_rates.set_index(\"date\")\n",
    "\n",
    "interest_rates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Payoff Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trigger_price(S_path, trigger):\n",
    "    '''\n",
    "    Returns the price that triggered the event, if it exists, else None.\n",
    "    '''\n",
    "    # Return the first price that triggers the event\n",
    "    for price in S_path:\n",
    "        if price <= trigger:\n",
    "            return price\n",
    "        \n",
    "    return None\n",
    "\n",
    "\n",
    "def calculate_payoff(S_path, Y_0 = 1000, rate = 0.0985, years = 3):\n",
    "    '''\n",
    "    Computes the payoff of a simulated path.\n",
    "    '''\n",
    "    S_0 = 3790.38   # From factsheet\n",
    "    S_T = S_path[-1]\n",
    "    S_t1 = find_trigger_price(S_path, trigger = 0.90*S_0)   # 3,411.3420 \n",
    "    S_t2 = find_trigger_price(S_path, trigger = 0.85*S_0)   # 3,221.8230\n",
    "    S_t3 = find_trigger_price(S_path, trigger = 0.80*S_0)   # 3,032.3040\n",
    "\n",
    "    # Edge Case\n",
    "    if(S_t3 == 0 or S_t2 == 0 or S_t1 == 0):\n",
    "        return 0\n",
    "\n",
    "    # 1. Fixed returns independent of trigger events\n",
    "    Y_T = (0.55*Y_0) * (S_T/S_0)\n",
    "\n",
    "    # 2. Adjusted returns after trigger events\n",
    "    if S_t3 is not None:\n",
    "        multiplier = (S_T/S_t1 + S_T/S_t2 + S_T/S_t3)\n",
    "    elif S_t2 is not None:\n",
    "        multiplier = (S_T/S_t1 + S_T/S_t2)\n",
    "    elif S_t1 is not None:\n",
    "        multiplier = (S_T/S_t1)\n",
    "    else:\n",
    "        multiplier = 0.0\n",
    "    Y_T += (0.15*Y_0) * multiplier\n",
    "\n",
    "    # 3. Daily accrued interest of 9.85% p.a.\n",
    "    if S_t3 is not None:\n",
    "        principal = 0.0\n",
    "    elif S_t2 is not None:\n",
    "        principal = (0.15*Y_0)\n",
    "    elif S_t1 is not None:\n",
    "        principal = (0.30*Y_0)\n",
    "    else:\n",
    "        principal = (0.45*Y_0)\n",
    "    Y_T += principal * (1 + rate * years)\n",
    "    \n",
    "    assert Y_T >= 0.0   # Sanity Check\n",
    "    return Y_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_T = 0.0 \t   Performance of Asset = -100.00% \t Performance of Certificate = -100.00% \t Payoff = 0.00\n",
      "S_T = 2653.27 \t   Performance of Asset = -30.00% \t Performance of Certificate = -23.91% \t Payoff = 760.89\n",
      "S_T = 3032.3 \t   Performance of Asset = -20.00% \t Performance of Certificate = -13.04% \t Payoff = 869.59\n",
      "S_T = 3411.34 \t   Performance of Asset = -10.00% \t Performance of Certificate = -2.17% \t Payoff = 978.29\n",
      "S_T = 3790.38 \t   Performance of Asset = 0.00% \t Performance of Certificate = 8.70% \t Payoff = 1086.98\n",
      "S_T = 4169.42 \t   Performance of Asset = 10.00% \t Performance of Certificate = 19.57% \t Payoff = 1195.68\n",
      "S_T = 4548.46 \t   Performance of Asset = 20.00% \t Performance of Certificate = 30.44% \t Payoff = 1304.38\n",
      "S_T = 4927.49 \t   Performance of Asset = 30.00% \t Performance of Certificate = 41.31% \t Payoff = 1413.08\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Testing the payoff function with values in the factsheet (Flawed, all triggers are hit)\n",
    "S_0 = 3790.38\n",
    "S_path_partial = [3790.41, 3800.15, 3373.44, 4000.00, 3183.92, 2994.40]\n",
    "S_T = [0.0, 2653.27, 3032.3, 3411.34, 3790.38, 4169.42, 4548.46, 4927.49]\n",
    "\n",
    "for final_closing_price in S_T:\n",
    "    S_path = S_path_partial + [final_closing_price]\n",
    "    payoff = calculate_payoff(S_path)\n",
    "\n",
    "    print(f\"S_T = {final_closing_price} \\t   Performance of Asset = {100*(final_closing_price - S_0)/S_0:.2f}% \\t Performance of Certificate = {(payoff - 1000)/10:.2f}% \\t Payoff = {payoff:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Geometric Brownian Motion\n",
    "\n",
    "Implmentation of the Black-Scholes model for pricing. THe form derived from Ito's lemma was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def simulate_GBM(num_sim, S_0, r, sigma, delta_t, T, Z):  # NOTE: For exact GMB simply set r=mu while calling\n",
    "  # Initializations\n",
    "  v = r - 0.5*(sigma**2)\n",
    "  print(v)\n",
    "  num_periods = int(T/delta_t)\n",
    "  S_matrix = np.zeros(shape=(num_sim, num_periods + 1), dtype=np.float64)\n",
    "\n",
    "  # We are using the form derived by Ito's lemma \n",
    "  for i in range(num_sim):\n",
    "    S_matrix[i][0] = S_0\n",
    "    for j in range(1, num_periods + 1):\n",
    "      log_diff = v*delta_t + (sigma*np.sqrt(delta_t) * Z[i][j-1])\n",
    "      S_matrix[i][j] = S_matrix[i][j-1]*np.exp(log_diff)\n",
    "\n",
    "  return S_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Variance Reduction for GBM\n",
    "\n",
    "Functions that implement,\n",
    "\n",
    "<ol> \n",
    "<li> Antithetic Variates\n",
    "<li> Control Variates\n",
    "<li> Empirical Martingale Simulation\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def simulate_GBM_AV(num_sim, S_0, r, sigma, delta_t, T, Z):\n",
    "  # Initializations\n",
    "  v = r - 0.5*(sigma**2)\n",
    "  num_periods = int(T/delta_t)\n",
    "  S_matrix = np.full(shape=(num_sim, num_periods + 1), fill_value = S_0, dtype=np.float64)\n",
    "  S_tilde_matrix = np.full(shape=(num_sim, num_periods + 1), fill_value = S_0, dtype=np.float64)\n",
    "\n",
    "  # Ito's lemma form (just a bit more concise)\n",
    "  for i in range(num_sim):\n",
    "    S_matrix[i][0] = S_0\n",
    "    S_tilde_matrix[i][0] = S_0\n",
    "    for j in range(1, num_periods + 1):\n",
    "        S_matrix[i][j] = S_matrix[i][j-1]*np.exp(v*delta_t + (sigma*np.sqrt(delta_t) * Z[i][j-1]))\n",
    "        S_tilde_matrix[i][j] = S_tilde_matrix[i][j-1]*np.exp(v*delta_t - (sigma*np.sqrt(delta_t) * Z[i][j-1]))  # Negative Z(.)  \n",
    "  \n",
    "  return np.vstack((S_matrix, S_tilde_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def simulate_GBM_EMS(num_sim, S_0, r, sigma, delta_t, T, Z):\n",
    "  # Initializations\n",
    "  num_periods = int(T/delta_t)\n",
    "  S_matrix = np.full(shape=(num_sim, num_periods + 1), fill_value = S_0, dtype=np.float64)\n",
    "  Z_matrix = np.full(shape=(num_sim + 1, num_periods + 1), fill_value = S_0, dtype=np.float64)\n",
    "\n",
    "  # Simulating the GBM path and set the first coloumn of S_matrix\n",
    "  gbm_path = simulate_GBM(num_sim, S_0, r, sigma, delta_t, T, Z=Z)\n",
    "  S_matrix[:, 0] = gbm_path[:, 0]\n",
    "  \n",
    "  # Correcting the path using EMS\n",
    "  for j in range(1, num_periods+1):\n",
    "    Z_matrix[:num_sim, j-1] = (S_matrix[:, j-1] * gbm_path[:, j])/gbm_path[:, j-1]\n",
    "    Z_matrix[num_sim, j-1] = np.exp(-r * ((j-1) * delta_t)) * np.mean(Z_matrix[:num_sim, j-1])\n",
    "    S_matrix[:, j] = (gbm_path[:, 0] * Z_matrix[:num_sim, j-1])/Z_matrix[num_sim, j-1]\n",
    "\n",
    "  return S_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK: For the Control Variate whether we use the asset prices or product prices for the covariance step. Also check Z_1 and Z_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit  # Need to use some pythonic capabilities for this function\n",
    "def simulate_GBM_CV(num_sim, S_0, r, sigma, delta_t, T, Z_pilot, Z_new, use_minimum=False):\n",
    "  \"\"\"\n",
    "  N_1 == N_2 == num_sim in our implementation\n",
    "  If use_minmum = True, we set S_T as the respective minimum price of for each GBM path\n",
    "  \"\"\"\n",
    "  # Generating a pilot of N_1 prices\n",
    "  gbm_path_pilot = simulate_GBM(num_sim, S_0, r, sigma, delta_t, T, Z_pilot)\n",
    "  payoff_pilot = np.exp(-r*T)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=gbm_path_pilot)\n",
    "\n",
    "  # Calulating c*\n",
    "  S_T_vector_pilot = [min(i) for i in gbm_path_pilot] if use_minimum else [i[-1] for i in gbm_path_pilot]\n",
    "  covariance_matrix = np.cov(payoff_pilot, S_T_vector_pilot)\n",
    "  c_star = -covariance_matrix[0][1]/(S_0**2 * np.exp(2*r*T) * (np.exp(sigma**2 * T) - 1))    # By the martingale property\n",
    "  \n",
    "  # Simulating N_2 new prices\n",
    "  gbm_path_new = simulate_GBM(num_sim, S_0, r, sigma, delta_t, T, Z=Z_new)\n",
    "  payoff_new = np.exp(-r*T)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=gbm_path_new)\n",
    "  \n",
    "  # Finally, computing the control variates\n",
    "  S_T_vector_new = [min(i) for i in gbm_path_new] if use_minimum else [i[-1] for i in gbm_path_new]\n",
    "  payoff_CV = payoff_new + c_star * (S_T_vector_new - S_0 * np.exp(r*T))\n",
    "\n",
    "  return payoff_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Backtesting GBM\n",
    "\n",
    "We take 252 day long windows of data for each iteration.\n",
    "\n",
    "eg: The first window begins on 9th August, 2022 and ends on 9th August, 2023 and we price the product on 10th August."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters and Rolling Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753\n"
     ]
    }
   ],
   "source": [
    "# Create a market calendar for date handling\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "product_lifetime = nyse.schedule(start_date='2022-07-14', end_date='2025-07-14')\n",
    "print(len(product_lifetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for each set of simulations\n",
    "num_sim = 10000    # Push to 1,000,000\n",
    "delta_t = 1/252\n",
    "num_periods = len(product_lifetime)\n",
    "T = num_periods/252\n",
    "# T is in years\n",
    "# delta t is also in years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One set of simulations for each date in [start_date, end_date]\n",
    "window_size = 252\n",
    "start_date = pd.to_datetime(\"2023-08-09\")\n",
    "end_date = pd.to_datetime(\"2022-10-20\")\n",
    "#end_date = pd.to_datetime(\"2022-11-09\")  # TODO: Update dataset\n",
    "\n",
    "simulation_dates = asset_prices.index[asset_prices.index >= start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected data for 52 windows of size 252 each.\n"
     ]
    }
   ],
   "source": [
    "# We shall sample a window of size 252 from the historical data (EXCLUDING the current date)\n",
    "backtest_windows = []\n",
    "\n",
    "for window_end_date in simulation_dates:\n",
    "    # Jump back 252 points\n",
    "    window_start_index = asset_prices.index.get_loc(window_end_date) - window_size\n",
    "    assert window_start_index >= 0\n",
    "\n",
    "    # Slice the dataset according to the window\n",
    "    window_start_date = asset_prices.index[window_start_index]\n",
    "    window_asset_data = asset_prices[(asset_prices.index >= window_start_date) & (asset_prices.index < window_end_date)]    # CHECK THIS with TA\n",
    "\n",
    "    # Collect all the windows\n",
    "    assert len(window_asset_data) == window_size\n",
    "    backtest_windows.append(np.array(window_asset_data[\"value\"]))\n",
    "\n",
    "print(f\"Collected data for {len(backtest_windows)} windows of size {window_size} each.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpolating the Interest Rate Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 12)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maturities = np.array([1/12, 2/12, 3/12, 4/12, 6/12, 1, 2, 3, 5, 7, 10, 20, 30])\n",
    "interest_rates.columns = maturities\n",
    "\n",
    "# The 4 month interest rate is a bit sparse\n",
    "interest_rates = interest_rates.dropna(how='any', axis=1)\n",
    "maturities = interest_rates.columns.to_numpy()\n",
    "interest_rates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate not found for date 2023-10-09 00:00:00, using the rate from the previous date.\n"
     ]
    }
   ],
   "source": [
    "curves = []\n",
    "for date in simulation_dates:\n",
    "    try:\n",
    "        interest_rate = interest_rates.loc[date].to_numpy()\n",
    "        curve_fit, status = calibrate_ns_ols(maturities, interest_rate)\n",
    "        curves.append(curve_fit)\n",
    "\n",
    "    except KeyError:\n",
    "        # Handle the case where the rate is not found\n",
    "        print(f\"Rate not found for date {date}, using the rate from the previous date.\")    # CHECK THIS!\n",
    "        previous_date = interest_rates.index[interest_rates.index <= date].max()\n",
    "        corrected_rate = interest_rates.loc[previous_date].to_numpy()\n",
    "        curve_fit, status = calibrate_ns_ols(maturities, corrected_rate)\n",
    "        curves.append(curve_fit)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for date {date}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lognormal_statistics(prices, delta_t):\n",
    "  log_data = np.log(prices)\n",
    "  log_returns = log_data[1:] - log_data[:-1]\n",
    "  mu = np.mean(log_returns)/delta_t\n",
    "  sigma = np.std(log_returns, ddof=1)/np.sqrt(delta_t)\n",
    "  return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a common random variable/common randomness matrix\n",
    "Z_matrix = np.random.normal(0, 1, size=(len(simulation_dates), num_sim, num_periods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the Simulations aka The Exciting Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.017339435138420876\n",
      "-0.01714791332378645\n",
      "-0.01714486044762865\n",
      "-0.01699835786812014\n",
      "-0.017007203203444125\n",
      "-0.017074151155618642\n",
      "-0.017077123702366404\n",
      "-0.01710669554238051\n",
      "-0.017018275024585947\n",
      "-0.016799283207837724\n"
     ]
    }
   ],
   "source": [
    "# GBM without Variance Reduction\n",
    "GBM_expected_values = []\n",
    "\n",
    "for date, prices in zip(simulation_dates, backtest_windows):\n",
    "  # Convert date to index (so we can lookup prices and interest rate curves)\n",
    "  date_index = simulation_dates.get_loc(date)\n",
    "\n",
    "  # Estimate r\n",
    "  #delta = num_periods - date_index     # Correct this \n",
    "  delta = len(product_lifetime[date:])\n",
    "  tau = delta / 252 ### time diff in years\n",
    "  curve_fit = curves[date_index]\n",
    "  r = curve_fit(tau)/100 ### yearly interest\n",
    "  # Calulcate mu and sigma (we discard mu)\n",
    "  _, sigma = get_lognormal_statistics(prices, delta_t)  ### sigma is daily variance\n",
    "  eff_r = r-1.67/100\n",
    "\n",
    "  # Simulate prices, calculate payoff and expected value\n",
    "  simulated_prices = simulate_GBM(num_sim, prices[-1], eff_r/252, sigma, delta_t, tau, Z=Z_matrix[date_index])\n",
    "  payoffs = np.exp(-eff_r*tau)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=simulated_prices)\n",
    "  expected_value = np.mean(payoffs)\n",
    "  GBM_expected_values.append(expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM with Antithetic Variance Reduction\n",
    "GBM_AV_expected_values = []\n",
    "\n",
    "for date, prices in zip(simulation_dates, backtest_windows):\n",
    "  # Convert date to index (so we can lookup prices and interest rate curves)\n",
    "  date_index = simulation_dates.get_loc(date)\n",
    "\n",
    "  # Estimate r\n",
    "  delta = len(product_lifetime[date:])\n",
    "  tau = delta / 252\n",
    "  curve_fit = curves[date_index]\n",
    "  r = curve_fit(tau)/100\n",
    "  eff_r = r-1.67/100\n",
    "\n",
    "  # Calulcate mu and sigma (we discard mu)\n",
    "  _, sigma = get_lognormal_statistics(prices, delta_t)\n",
    "  \n",
    "  # Simulate prices, calculate payoff and expected value\n",
    "  simulated_prices = simulate_GBM_AV(int(num_sim/2), prices[-1], eff_r/252, sigma, delta_t, tau, Z=Z_matrix[date_index])\n",
    "  payoffs = np.exp(-eff_r*tau)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=simulated_prices)\n",
    "  expected_value = np.mean(payoffs)\n",
    "  GBM_AV_expected_values.append(expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM with EMS Variance Reduction\n",
    "GBM_EMS_expected_values = []\n",
    "\n",
    "for date, prices in zip(simulation_dates, backtest_windows):\n",
    "  # Convert date to index (so we can lookup prices and interest rate curves)\n",
    "  date_index = simulation_dates.get_loc(date)\n",
    "\n",
    "  # Estimate r\n",
    "  delta = len(product_lifetime[date:])\n",
    "  tau = delta / 252\n",
    "  curve_fit = curves[date_index]\n",
    "  r = curve_fit(tau)/100\n",
    "  eff_r = r-1.67/100\n",
    "\n",
    "  # Calulcate mu and sigma (we discard mu)\n",
    "  _, sigma = get_lognormal_statistics(prices, delta_t)\n",
    "\n",
    "  # Simulate prices, calculate payoff and expected value\n",
    "  simulated_prices = simulate_GBM_EMS(num_sim, prices[-1], eff_r/252, sigma, delta_t, tau, Z=Z_matrix[date_index])\n",
    "  payoffs = np.exp(-eff_r*tau)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=simulated_prices)\n",
    "  expected_value = np.mean(payoffs)\n",
    "  GBM_EMS_expected_values.append(expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GBM with Control Variate Variance Reduction\n",
    "# GBM_CV_expected_values = []\n",
    "\n",
    "# for date, prices in zip(simulation_dates, backtest_windows):\n",
    "#   # Convert date to index (so we can lookup prices and interest rate curves)\n",
    "#   date_index = simulation_dates.get_loc(date)\n",
    "\n",
    "#   # Estimate r\n",
    "#   delta = len(product_lifetime[date:])\n",
    "#   tau = delta / 252\n",
    "#   curve_fit = curves[date_index]\n",
    "#   r = curve_fit(tau)/100\n",
    "#   eff_r = r-1.67/100\n",
    "\n",
    "#   # Calulcate mu and sigma (we discard mu)\n",
    "#   _, sigma = get_lognormal_statistics(prices, delta_t)\n",
    "\n",
    "#   # We need to sample another Z, independently, for simulating the initial pilot prices\n",
    "#   Z_pilot = np.random.normal(0, 1, size=(num_sim, num_periods))\n",
    "#   Z_new = Z_matrix[date_index]\n",
    "#   assert Z_pilot.shape == Z_new.shape\n",
    "\n",
    "#   # Simulate payoff and expected value\n",
    "#   payoffs = simulate_GBM_CV(num_sim, prices[-1], eff_r/252, sigma, delta_t, tau, Z_pilot=Z_pilot, Z_new=Z_new)\n",
    "#   expected_value = np.mean(payoffs)\n",
    "#   GBM_CV_expected_values.append(expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GBM with Control Variate Variance Reduction, using minimum price as control\n",
    "# GBM_CV_Min_expected_values = []\n",
    "\n",
    "# for date, prices in zip(simulation_dates, backtest_windows):\n",
    "#   # Convert date to index (so we can lookup prices and interest rate curves)\n",
    "#   date_index = simulation_dates.get_loc(date)\n",
    "\n",
    "#   # Estimate r\n",
    "#   delta = len(product_lifetime[date:])\n",
    "#   tau = delta / 252\n",
    "#   curve_fit = curves[date_index]\n",
    "#   r = curve_fit(tau)/100\n",
    "#   eff_r = r-1.67/100\n",
    "\n",
    "#   # Calulcate mu and sigma (we discard mu)\n",
    "#   _, sigma = get_lognormal_statistics(prices, delta_t)\n",
    "\n",
    "#   # We need to sample another Z, independently, for simulating the initial pilot prices\n",
    "#   Z_pilot = np.random.normal(0, 1, size=(num_sim, num_periods))\n",
    "#   Z_new = Z_matrix[date_index]\n",
    "#   assert Z_pilot.shape == Z_new.shape\n",
    "\n",
    "#   # Simulate payoff and expected value\n",
    "#   payoffs = simulate_GBM_CV(num_sim, prices[-1], eff_r/252, sigma, delta_t, tau, Z_pilot=Z_pilot, Z_new=Z_new, use_minimum=True)\n",
    "#   expected_value = np.mean(payoffs)\n",
    "#   GBM_CV_Min_expected_values.append(expected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the Results aka The Moment of Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_reults = pd.DataFrame(index=simulation_dates)\n",
    "product_prices = product_prices[product_prices.index >= start_date]\n",
    "\n",
    "# For some reason the product was priced on Labour Day\n",
    "try:\n",
    "    product_prices = product_prices.drop(pd.to_datetime(\"2023-09-04\"))  # Labour day nonesense\n",
    "except:\n",
    "    print(\"Labour Day price was already removed!\")\n",
    "assert len(product_prices) == len(simulation_reults)\n",
    "\n",
    "# Gather data into a single dataframe\n",
    "simulation_reults['Actual'] = product_prices[\"value\"]\n",
    "simulation_reults['GBM'] = GBM_expected_values\n",
    "simulation_reults['AV'] = GBM_AV_expected_values\n",
    "simulation_reults['EMS'] = GBM_EMS_expected_values\n",
    "# simulation_reults['CV'] = GBM_CV_expected_values\n",
    "# simulation_reults['CV_Min'] = GBM_CV_Min_expected_values\n",
    "\n",
    "simulation_reults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "plt.title('Backtesting ',fontdict={\"fontsize\":18})\n",
    "\n",
    "simulation_reults['Actual'].plot(legend=True)\n",
    "simulation_reults['GBM'].plot(legend=True,style=\"--\")\n",
    "simulation_reults['AV'].plot(legend=True,style=\"--\")\n",
    "simulation_reults['EMS'].plot(legend=True,style=\"--\")\n",
    "# simulation_reults['CV'].plot(legend=True,style=\"--\")\n",
    "# simulation_reults['CV_Min'].plot(legend=True,style=\"--\")\n",
    "\n",
    "plt.xlabel('Market Days')\n",
    "plt.ylabel('Derivative Price in USD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hmm maybe the Error Decreased?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abs_error=mean_absolute_error(simulation_reults['Actual'].to_list(),simulation_reults['GBM'].to_list())\n",
    "mean_sq_error=mean_squared_error(simulation_reults['Actual'].to_list(),simulation_reults['GBM'].to_list())\n",
    "print(f'Mean Absolute Error for GBM:\\t\\t{mean_abs_error}')\n",
    "print(f'Mean Squared Error for GBM:\\t\\t{mean_sq_error}\\n')\n",
    "\n",
    "mean_abs_error=mean_absolute_error(simulation_reults['Actual'].to_list(),simulation_reults['AV'].to_list())\n",
    "mean_sq_error=mean_squared_error(simulation_reults['Actual'].to_list(),simulation_reults['AV'].to_list())\n",
    "print(f'Mean Absolute Error for GBM with AV:\\t{mean_abs_error}')\n",
    "print(f'Mean Squared Error for GBM with AV:\\t{mean_sq_error}\\n')\n",
    "\n",
    "mean_abs_error=mean_absolute_error(simulation_reults['Actual'].to_list(),simulation_reults['EMS'].to_list())\n",
    "mean_sq_error=mean_squared_error(simulation_reults['Actual'].to_list(),simulation_reults['EMS'].to_list())\n",
    "print(f'Mean Absolute Error for GBM with EMS:\\t{mean_abs_error}')\n",
    "print(f'Mean Squared Error for GBM with EMS:\\t{mean_sq_error}\\n')   \n",
    "\n",
    "mean_abs_error=mean_absolute_error(simulation_reults['Actual'].to_list(),simulation_reults['CV'].to_list())\n",
    "mean_sq_error=mean_squared_error(simulation_reults['Actual'].to_list(),simulation_reults['CV'].to_list())\n",
    "print(f'Mean Absolute Error for GBM with CV:\\t{mean_abs_error}')\n",
    "print(f'Mean Squared Error for GBM with CV:\\t{mean_sq_error}\\n')\n",
    "\n",
    "mean_abs_error=mean_absolute_error(simulation_reults['Actual'].to_list(),simulation_reults['CV_Min'].to_list())\n",
    "mean_sq_error=mean_squared_error(simulation_reults['Actual'].to_list(),simulation_reults['CV_Min'].to_list())\n",
    "print(f'Mean Absolute Error with CV using min:\\t{mean_abs_error}')\n",
    "print(f'Mean Squared Error with CV using min:\\t{mean_sq_error}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Estimating Sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM without Variance Reduction\n",
    "GBM_expected_values = []\n",
    "GBM_expected_values_plus_h = []\n",
    "GBM_expected_values_minus_h = []\n",
    "\n",
    "for date, prices in zip(simulation_dates, backtest_windows):\n",
    "  # Convert date to index (so we can lookup prices and interest rate curves)\n",
    "  date_index = simulation_dates.get_loc(date)\n",
    "\n",
    "  # Estimate r\n",
    "  delta = len(product_lifetime[date:])\n",
    "  tau = delta / 252\n",
    "  curve_fit = curves[date_index]\n",
    "  r = curve_fit(tau)/100\n",
    "\n",
    "  # Calulcate mu and sigma (we discard mu)\n",
    "  _, sigma = get_lognormal_statistics(prices, delta_t)\n",
    "\n",
    "  # Set h\n",
    "  h = 0.01 * 3790.38   # (St = 3790.38 from factsheet)\n",
    "\n",
    "  # Simulate prices and base payoffs\n",
    "  simulated_prices = simulate_GBM(num_sim, prices[-1], r, sigma, delta_t, tau, Z=Z_matrix[date_index])\n",
    "  payoffs = np.exp(-r*tau)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=simulated_prices)\n",
    "  expected_value = np.mean(payoffs)\n",
    "  GBM_expected_values.append(expected_value)\n",
    "\n",
    "  # Simulate the increased scenario, St + h\n",
    "  simulated_prices_plus_h = simulated_prices + h  # Increase entire path by h\n",
    "  payoffs_plus_h = np.exp(-r*tau)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=simulated_prices_plus_h)\n",
    "  expected_value_plus_h = np.mean(payoffs_plus_h)\n",
    "  GBM_expected_values_plus_h.append(expected_value_plus_h)\n",
    "\n",
    "  # Simulate the decreased scenario, St - h\n",
    "  simulated_prices_minus_h = simulated_prices - h  # Decrease entire path by h\n",
    "  payoffs_minus_h = np.exp(-r*tau)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=simulated_prices_minus_h)\n",
    "  expected_value_minus_h = np.mean(payoffs_minus_h)\n",
    "  GBM_expected_values_minus_h.append(expected_value_minus_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change type from list to np array\n",
    "fS = np.array(GBM_expected_values)\n",
    "fS_plus_h = np.array(GBM_expected_values_plus_h)\n",
    "fS_minus_h = np.array(GBM_expected_values_minus_h)\n",
    "\n",
    "# Compute Delta and Gamma (using FDM)\n",
    "deltas = math.exp(-r*tau) * (fS_plus_h - fS_minus_h) / (2 * h) ## QUESTION: should this factor be included math.exp(-r*tau) (again)\n",
    "gammas = math.exp(-r*tau) * (fS_plus_h - 2 * fS + fS_minus_h) / (h ** 2)\n",
    "\n",
    "# Create a DataFrame for results\n",
    "greeks_results = pd.DataFrame(index=simulation_dates)\n",
    "greeks_results['Delta'] = deltas\n",
    "greeks_results['Gamma'] = gammas\n",
    "\n",
    "# Plot Delta\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(greeks_results.index, greeks_results['Delta'], label='Delta', color='tab:red', linestyle='--')\n",
    "plt.title('Delta', fontsize=18)\n",
    "plt.xlabel('Market Days', fontsize=16)\n",
    "plt.ylabel('Delta Value in USD', fontsize=16)\n",
    "plt.tick_params(axis='x', labelsize=16)\n",
    "plt.tick_params(axis='y', labelsize=16)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Gamma\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(greeks_results.index, greeks_results['Gamma'], label='Gamma', color='tab:blue', linestyle='--')\n",
    "plt.title('Gamma', fontsize=18)\n",
    "plt.xlabel('Market Days', fontsize=16)\n",
    "plt.ylabel('Gamma Value in USD', fontsize=16)\n",
    "plt.tick_params(axis='x', labelsize=16)\n",
    "plt.tick_params(axis='y', labelsize=16)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Delta: ', np.mean(deltas), '\\nGamma: ', np.mean(gammas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mh4518",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
