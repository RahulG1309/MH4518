{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MH4518 Group Project\n",
    "\n",
    "Product: https://derivative.credit-suisse.com/ch/ch/en/detail/drop-back-certificate-s-p-500/CH1199361879/119936187\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initial Set-up\n",
    "\n",
    "<ol>\n",
    "<li> Set directories\n",
    "<li> Install dependencies\n",
    "<li> Import libraries\n",
    "<li> Suppress Warnings (Optional)\n",
    "</ol>\n",
    "\n",
    "NOTE: Ensure you are using the correct kernel to run the Jupyter Notebook with the correctly set root driectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "# Set the root directory accordingly\n",
    "ROOT_DIR = \"D:\\Coding\\MH4518\"\n",
    "os.chdir(ROOT_DIR)\n",
    "#sys.path.append(ROOT_DIR)\n",
    "\n",
    "# These directories are set relative to root\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "SAVE_DIR = os.path.join(ROOT_DIR, \"simulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional libraries using pip\n",
    "#! pip install -r requirements.txt\n",
    "\n",
    "# Or if you have Conda installed (reccommended)\n",
    "# conda env create -f environment.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "from numba import jit, njit\n",
    "from nelson_siegel_svensson.calibrate import calibrate_ns_ols\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Suppresing the deprecation notices while using numba and matplotlib (reccommended)\n",
    "import warnings\n",
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "\n",
    "warnings.filterwarnings('ignore', module = \"matplotlib\\..*\" )\n",
    "warnings.filterwarnings('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=NumbaPendingDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading Data\n",
    "\n",
    "The asset and product prices as well as the interest and dividend rates were collected and preprocessed using the notebook present in the `/data` directory.\n",
    "\n",
    "<ol>\n",
    "<li> daily_interest_rates.csv\n",
    "<li> asset_prices_processed.csv\n",
    "<li> product_prices_processed.csv\n",
    "<li> SPY_quarterly_dividend_rates.csv\n",
    "<li> VIX_annual_implied_volatility_rates.csv\n",
    "</ol>\n",
    "<br>\n",
    "\n",
    "However for our simulations we will only focus on the following time period,\n",
    "\n",
    "<li> Start date: 09-08-2022\n",
    "<li> End date: 09-11-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load asset prices\n",
    "asset_prices = pd.read_csv(os.path.join(DATA_DIR, \"asset_prices_processed.csv\"))\n",
    "asset_prices[\"date\"] = pd.to_datetime(asset_prices[\"date\"])\n",
    "asset_prices = asset_prices.set_index(\"date\")\n",
    "\n",
    "# Load product prices\n",
    "product_prices = pd.read_csv(os.path.join(DATA_DIR, \"product_prices_processed.csv\"))\n",
    "product_prices[\"date\"] = pd.to_datetime(product_prices[\"date\"])\n",
    "product_prices = product_prices.set_index(\"date\")\n",
    "\n",
    "# Load daily interest rates\n",
    "interest_rates = pd.read_csv(os.path.join(DATA_DIR, \"daily_interest_rates.csv\"))\n",
    "interest_rates[\"date\"] = pd.to_datetime(interest_rates[\"date\"])\n",
    "interest_rates = interest_rates.set_index(\"date\")\n",
    "\n",
    "# Load quarterly dividend rates\n",
    "dividend_rates = pd.read_csv(os.path.join(DATA_DIR, \"SPY_quarterly_dividend_rates.csv\"))\n",
    "dividend_rates[\"date\"] = pd.to_datetime(dividend_rates[\"date\"])\n",
    "dividend_rates = dividend_rates.set_index(\"date\")\n",
    "\n",
    "# Load annual implied volatility rates\n",
    "implied_volatility_rates = pd.read_csv(os.path.join(DATA_DIR, \"VIX_annual_implied_volatility_rates.csv\"))\n",
    "implied_volatility_rates[\"date\"] = pd.to_datetime(implied_volatility_rates[\"date\"])\n",
    "implied_volatility_rates = implied_volatility_rates.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-07-19</th>\n",
       "      <td>24.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-20</th>\n",
       "      <td>23.879999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-21</th>\n",
       "      <td>23.110001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-22</th>\n",
       "      <td>23.030001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-25</th>\n",
       "      <td>23.360001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                value\n",
       "date                 \n",
       "2022-07-19  24.500000\n",
       "2022-07-20  23.879999\n",
       "2022-07-21  23.110001\n",
       "2022-07-22  23.030001\n",
       "2022-07-25  23.360001"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the implied volatility rates (for example)\n",
    "implied_volatility_rates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Payoff Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trigger_price(S_path, trigger):\n",
    "    '''\n",
    "    Returns the price that triggered the event, if it exists, else None.\n",
    "    '''\n",
    "    # Return the first price that triggers the event\n",
    "    for price in S_path:\n",
    "        if price <= trigger:\n",
    "            return price\n",
    "        \n",
    "    return None\n",
    "\n",
    "\n",
    "def calculate_payoff(S_path, Y_0 = 1000, rate = 0.0985, years = 3):\n",
    "    '''\n",
    "    Computes the payoff of a simulated path.\n",
    "    '''\n",
    "    S_0 = 3790.38   # From factsheet\n",
    "    S_t1 = find_trigger_price(S_path, trigger = 3411.3420)   # 0.90 * S_0\n",
    "    S_t2 = find_trigger_price(S_path, trigger = 3221.8230)   # 0.85 * S_0\n",
    "    S_t3 = find_trigger_price(S_path, trigger = 3032.3040)   # 0.80 * S_0\n",
    "    S_T = S_path[-1]\n",
    "\n",
    "    # Edge Case\n",
    "    if(S_t3 == 0 or S_t2 == 0 or S_t1 == 0):\n",
    "        return 0\n",
    "\n",
    "    # 1. Fixed returns independent of trigger events\n",
    "    Y_T = (0.55*Y_0) * (S_T/S_0)\n",
    "\n",
    "    # 2. Adjusted returns after trigger events\n",
    "    if S_t3 is not None:\n",
    "        multiplier = (S_T/S_t1 + S_T/S_t2 + S_T/S_t3)\n",
    "    elif S_t2 is not None:\n",
    "        multiplier = (S_T/S_t1 + S_T/S_t2)\n",
    "    elif S_t1 is not None:\n",
    "        multiplier = (S_T/S_t1)\n",
    "    else:\n",
    "        multiplier = 0.0\n",
    "    Y_T += (0.15*Y_0) * multiplier\n",
    "\n",
    "    # 3. Daily accrued interest of 9.85% p.a.\n",
    "    if S_t3 is not None:\n",
    "        principal = 0.0\n",
    "    elif S_t2 is not None:\n",
    "        principal = (0.15*Y_0)\n",
    "    elif S_t1 is not None:\n",
    "        principal = (0.30*Y_0)\n",
    "    else:\n",
    "        principal = (0.45*Y_0)\n",
    "    Y_T += principal * (1 + rate * years)\n",
    "    \n",
    "    assert Y_T >= 0.0   # Sanity Check\n",
    "    return Y_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_T = 0.0 \t   Performance of Asset = -100.00% \t Performance of Certificate = -100.00% \t Payoff = 0.00\n",
      "S_T = 2653.27 \t   Performance of Asset = -30.00% \t Performance of Certificate = -23.91% \t Payoff = 760.89\n",
      "S_T = 3032.3 \t   Performance of Asset = -20.00% \t Performance of Certificate = -13.04% \t Payoff = 869.59\n",
      "S_T = 3411.34 \t   Performance of Asset = -10.00% \t Performance of Certificate = -2.17% \t Payoff = 978.29\n",
      "S_T = 3790.38 \t   Performance of Asset = 0.00% \t Performance of Certificate = 8.70% \t Payoff = 1086.98\n",
      "S_T = 4169.42 \t   Performance of Asset = 10.00% \t Performance of Certificate = 19.57% \t Payoff = 1195.68\n",
      "S_T = 4548.46 \t   Performance of Asset = 20.00% \t Performance of Certificate = 30.44% \t Payoff = 1304.38\n",
      "S_T = 4927.49 \t   Performance of Asset = 30.00% \t Performance of Certificate = 41.31% \t Payoff = 1413.08\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Testing the payoff function with values in the factsheet (Flawed, all triggers are hit)\n",
    "S_0 = 3790.38\n",
    "S_path_partial = [3790.41, 3800.15, 3373.44, 4000.00, 3183.92, 2994.40]\n",
    "S_T = [0.0, 2653.27, 3032.3, 3411.34, 3790.38, 4169.42, 4548.46, 4927.49]\n",
    "\n",
    "for final_closing_price in S_T:\n",
    "    S_path = S_path_partial + [final_closing_price]\n",
    "    payoff = calculate_payoff(S_path)\n",
    "\n",
    "    print(f\"S_T = {final_closing_price} \\t   Performance of Asset = {100*(final_closing_price - S_0)/S_0:.2f}% \\t Performance of Certificate = {(payoff - 1000)/10:.2f}% \\t Payoff = {payoff:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Geometric Brownian Motion\n",
    "\n",
    "Implmentation of the Black-Scholes model for pricing. THe form derived from Ito's lemma was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def simulate_GBM(num_sim, S_0, r, sigma, delta_t, T, Z):  # NOTE: For exact GMB simply set r = mu while calling\n",
    "  \"\"\"\n",
    "  r is the daily interest rate\n",
    "  sigma is daily volatility\n",
    "  T is actually tau = T - t (in years)\n",
    "  delta_t is 1 / 252\n",
    "  Z is the random variates sampled from N(0, 1)\n",
    "  \"\"\"\n",
    "  # Initializations\n",
    "  v = r - 0.5*(sigma**2)\n",
    "  num_periods = int(T/delta_t)\n",
    "  S_matrix = np.zeros(shape=(num_sim, num_periods + 1), dtype=np.float64)\n",
    "\n",
    "  # We are using the form derived by Ito's lemma \n",
    "  for i in range(num_sim):\n",
    "    S_matrix[i][0] = S_0\n",
    "    for j in range(1, num_periods + 1):\n",
    "      log_diff = v*delta_t + (sigma*np.sqrt(delta_t) * Z[i][j-1])\n",
    "      S_matrix[i][j] = S_matrix[i][j-1]*np.exp(log_diff)\n",
    "\n",
    "  return S_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Variance Reduction for GBM\n",
    "\n",
    "Functions that implement,\n",
    "\n",
    "<ol> \n",
    "<li> Antithetic Variates\n",
    "<li> Control Variates\n",
    "<li> Empirical Martingale Simulation\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def simulate_GBM_AV(num_sim, S_0, r, sigma, delta_t, T, Z):\n",
    "  \"\"\"\n",
    "  r is the daily interest rate\n",
    "  sigma is daily volatility\n",
    "  T is actually tau = T - t (in years)\n",
    "  delta_t is 1 / 252\n",
    "  Z is the random variates sampled from N(0, 1)\n",
    "  \"\"\"\n",
    "  # Initializations\n",
    "  v = r - 0.5*(sigma**2)\n",
    "  num_periods = int(T/delta_t)\n",
    "  S_matrix = np.full(shape=(num_sim, num_periods + 1), fill_value = S_0, dtype=np.float64)\n",
    "  S_tilde_matrix = np.full(shape=(num_sim, num_periods + 1), fill_value = S_0, dtype=np.float64)\n",
    "\n",
    "  # Ito's lemma form (just a bit more concise)\n",
    "  for i in range(num_sim):\n",
    "    S_matrix[i][0] = S_0\n",
    "    S_tilde_matrix[i][0] = S_0\n",
    "    for j in range(1, num_periods + 1):\n",
    "        S_matrix[i][j] = S_matrix[i][j-1]*np.exp(v*delta_t + (sigma*np.sqrt(delta_t) * Z[i][j-1]))\n",
    "        S_tilde_matrix[i][j] = S_tilde_matrix[i][j-1]*np.exp(v*delta_t - (sigma*np.sqrt(delta_t) * Z[i][j-1]))  # Negative Z(.)  \n",
    "  \n",
    "  return np.vstack((S_matrix, S_tilde_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def simulate_GBM_EMS(num_sim, S_0, r, sigma, delta_t, T, Z):\n",
    "  \"\"\"\n",
    "  r is the daily interest rate\n",
    "  sigma is daily volatility\n",
    "  T is actually tau = T - t (in years)\n",
    "  delta_t is 1 / 252\n",
    "  Z is the random variates sampled from N(0, 1)\n",
    "  \"\"\"\n",
    "  # Initializations\n",
    "  num_periods = int(T/delta_t)\n",
    "  S_matrix = np.full(shape=(num_sim, num_periods + 1), fill_value = S_0, dtype=np.float64)\n",
    "  Z_matrix = np.full(shape=(num_sim + 1, num_periods + 1), fill_value = S_0, dtype=np.float64)\n",
    "\n",
    "  # Simulating the GBM path and set the first coloumn of S_matrix\n",
    "  gbm_path = simulate_GBM(num_sim, S_0, r, sigma, delta_t, T, Z=Z)\n",
    "  S_matrix[:, 0] = gbm_path[:, 0]\n",
    "  \n",
    "  # Correcting the path using EMS\n",
    "  for j in range(1, num_periods+1):\n",
    "    Z_matrix[:num_sim, j-1] = (S_matrix[:, j-1] * gbm_path[:, j]) / gbm_path[:, j-1]\n",
    "    Z_matrix[num_sim, j-1] = np.exp(-r * ((j-1) * delta_t)) * np.mean(Z_matrix[:num_sim, j-1])\n",
    "    S_matrix[:, j] = (gbm_path[:, 0] * Z_matrix[:num_sim, j-1]) / Z_matrix[num_sim, j-1]\n",
    "\n",
    "  return S_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit  # Need to use some pythonic capabilities for this function\n",
    "def simulate_GBM_CV(num_sim, S_0, r, sigma, delta_t, T, Z_pilot, Z_new, use_minimum=False):\n",
    "  \"\"\"\n",
    "  r is the daily interest rate\n",
    "  ...\n",
    "  N_1 == N_2 == num_sim in our implementation\n",
    "  If use_minmum = True, we set S_T as the respective minimum price of for each GBM path\n",
    "  \"\"\"\n",
    "  # Disambiguation of r and sigma\n",
    "  r_daily, r_yearly = r, (r * 252)     # Basically r_yearly is used in any exp(.) and r_daily is for the gbm simulations.\n",
    "  sigma_daily, sigma_yearly = sigma, (252 ** (1/2)) * sigma\n",
    "\n",
    "  # Generating a pilot of N_1 prices\n",
    "  gbm_path_pilot = simulate_GBM(num_sim, S_0, r_daily, sigma_daily, delta_t, T, Z=Z_pilot)\n",
    "  payoff_pilot = np.exp(-r_yearly*T)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=gbm_path_pilot)\n",
    "\n",
    "  # Calulating c*\n",
    "  S_T_vector_pilot = [min(path) for path in gbm_path_pilot] if use_minimum else [path[-1] for path in gbm_path_pilot]\n",
    "  covariance_matrix = np.cov(payoff_pilot, S_T_vector_pilot)\n",
    "  c_star = -covariance_matrix[0][1]/(S_0**2 * np.exp(2*r_yearly*T) * (np.exp(sigma_yearly**2 * T) - 1))    # By the martingale property\n",
    "  \n",
    "  # Simulating N_2 new prices\n",
    "  gbm_path_new = simulate_GBM(num_sim, S_0, r_daily, sigma_daily, delta_t, T, Z=Z_new)\n",
    "  payoff_new = np.exp(-r_yearly*T)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=gbm_path_new)\n",
    "  \n",
    "  # Finally, computing the control variates\n",
    "  S_T_vector_new = [min(path) for path in gbm_path_new] if use_minimum else [path[-1] for path in gbm_path_new]\n",
    "  payoff_CV = payoff_new + c_star * (S_T_vector_new - S_0 * np.exp(r_yearly*T))\n",
    "\n",
    "  return payoff_CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Backtesting GBM\n",
    "\n",
    "We take 252 day long windows of data for each iteration.\n",
    "\n",
    "eg: The first window begins on 9th August, 2022 and ends on 9th August, 2023 and we price the product on 10th August."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Parameters and Rolling Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753\n"
     ]
    }
   ],
   "source": [
    "# Create a market calendar for date handling\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "product_lifetime = nyse.schedule(start_date='2022-07-14', end_date='2025-07-14')\n",
    "print(len(product_lifetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for each set of simulations\n",
    "num_sim = 20000    # Push to 1,000,000\n",
    "delta_t = 1/252\n",
    "num_periods = len(product_lifetime)\n",
    "T = num_periods/252\n",
    "# T is in years\n",
    "# delta t_is also in years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 days\n",
      "Start Date: 2023-08-09 00:00:00; End date: 2023-11-09 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# One set of simulations for each date in [start_date, end_date]\n",
    "window_size = 252\n",
    "start_date = pd.to_datetime(\"2023-08-09\")\n",
    "end_date = pd.to_datetime(\"2023-11-09\")\n",
    "\n",
    "simulation_dates = product_prices.index[(product_prices.index >= start_date) & (product_prices.index <= end_date)]\n",
    "print(f\"{len(simulation_dates)} days\")\n",
    "print(f\"Start Date: {simulation_dates[0]}; End date: {simulation_dates[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset not priced on 2023-09-04 00:00:00. Using data up till the previous date!\n",
      "Asset not priced on 2023-11-09 00:00:00. Using data up till the previous date!\n",
      "Collected data for 67 windows of size 252 each.\n"
     ]
    }
   ],
   "source": [
    "# We shall sample a window of size 252 from the historical data (EXCLUDING the current date)\n",
    "backtest_windows = []   # Prices only\n",
    "backtest_windows_with_dates = []\n",
    "previous_window_end_date = None\n",
    "\n",
    "for window_end_date in simulation_dates:\n",
    "    # For each date the product was prices, we need 252 points BEFORE this date\n",
    "    try:\n",
    "        window_start_index = asset_prices.index.get_loc(window_end_date) - window_size\n",
    "    except:\n",
    "        window_start_index = asset_prices.index.get_loc(previous_window_end_date) - window_size + 1\n",
    "        print(f\"Asset not priced on {window_end_date}. Using data up till the previous date!\")\n",
    "\n",
    "    assert window_start_index >= 0\n",
    "\n",
    "    # Slice the dataset according to the window\n",
    "    window_start_date = asset_prices.index[window_start_index]\n",
    "    window_asset_data = asset_prices[(asset_prices.index >= window_start_date) & (asset_prices.index < window_end_date)]\n",
    "\n",
    "    # Collect all the windows\n",
    "    assert len(window_asset_data) == window_size\n",
    "    backtest_windows_with_dates.append(window_asset_data)   # For validatiuon purposes\n",
    "    backtest_windows.append(np.array(window_asset_data[\"value\"]))\n",
    "    \n",
    "    # For handling edge cases in the try-except block\n",
    "    previous_window_end_date = window_end_date\n",
    "\n",
    "print(f\"Collected data for {len(backtest_windows)} windows of size {window_size} each.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pricing asset on - \t\t2023-08-09 00:00:00.\n",
      "We have data till - \t2023-08-08 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-10 00:00:00.\n",
      "We have data till - \t2023-08-09 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-11 00:00:00.\n",
      "We have data till - \t2023-08-10 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-14 00:00:00.\n",
      "We have data till - \t2023-08-11 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-15 00:00:00.\n",
      "We have data till - \t2023-08-14 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-16 00:00:00.\n",
      "We have data till - \t2023-08-15 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-17 00:00:00.\n",
      "We have data till - \t2023-08-16 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-18 00:00:00.\n",
      "We have data till - \t2023-08-17 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-21 00:00:00.\n",
      "We have data till - \t2023-08-18 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-22 00:00:00.\n",
      "We have data till - \t2023-08-21 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-23 00:00:00.\n",
      "We have data till - \t2023-08-22 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-24 00:00:00.\n",
      "We have data till - \t2023-08-23 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-25 00:00:00.\n",
      "We have data till - \t2023-08-24 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-28 00:00:00.\n",
      "We have data till - \t2023-08-25 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-29 00:00:00.\n",
      "We have data till - \t2023-08-28 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-30 00:00:00.\n",
      "We have data till - \t2023-08-29 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-08-31 00:00:00.\n",
      "We have data till - \t2023-08-30 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-01 00:00:00.\n",
      "We have data till - \t2023-08-31 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-04 00:00:00.\n",
      "We have data till - \t2023-09-01 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-05 00:00:00.\n",
      "We have data till - \t2023-09-01 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-06 00:00:00.\n",
      "We have data till - \t2023-09-05 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-07 00:00:00.\n",
      "We have data till - \t2023-09-06 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-08 00:00:00.\n",
      "We have data till - \t2023-09-07 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-11 00:00:00.\n",
      "We have data till - \t2023-09-08 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-12 00:00:00.\n",
      "We have data till - \t2023-09-11 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-13 00:00:00.\n",
      "We have data till - \t2023-09-12 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-14 00:00:00.\n",
      "We have data till - \t2023-09-13 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-15 00:00:00.\n",
      "We have data till - \t2023-09-14 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-18 00:00:00.\n",
      "We have data till - \t2023-09-15 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-19 00:00:00.\n",
      "We have data till - \t2023-09-18 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-20 00:00:00.\n",
      "We have data till - \t2023-09-19 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-21 00:00:00.\n",
      "We have data till - \t2023-09-20 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-22 00:00:00.\n",
      "We have data till - \t2023-09-21 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-25 00:00:00.\n",
      "We have data till - \t2023-09-22 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-26 00:00:00.\n",
      "We have data till - \t2023-09-25 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-27 00:00:00.\n",
      "We have data till - \t2023-09-26 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-28 00:00:00.\n",
      "We have data till - \t2023-09-27 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-09-29 00:00:00.\n",
      "We have data till - \t2023-09-28 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-02 00:00:00.\n",
      "We have data till - \t2023-09-29 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-03 00:00:00.\n",
      "We have data till - \t2023-10-02 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-04 00:00:00.\n",
      "We have data till - \t2023-10-03 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-05 00:00:00.\n",
      "We have data till - \t2023-10-04 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-06 00:00:00.\n",
      "We have data till - \t2023-10-05 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-09 00:00:00.\n",
      "We have data till - \t2023-10-06 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-10 00:00:00.\n",
      "We have data till - \t2023-10-09 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-11 00:00:00.\n",
      "We have data till - \t2023-10-10 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-12 00:00:00.\n",
      "We have data till - \t2023-10-11 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-13 00:00:00.\n",
      "We have data till - \t2023-10-12 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-16 00:00:00.\n",
      "We have data till - \t2023-10-13 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-17 00:00:00.\n",
      "We have data till - \t2023-10-16 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-18 00:00:00.\n",
      "We have data till - \t2023-10-17 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-19 00:00:00.\n",
      "We have data till - \t2023-10-18 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-20 00:00:00.\n",
      "We have data till - \t2023-10-19 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-23 00:00:00.\n",
      "We have data till - \t2023-10-20 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-24 00:00:00.\n",
      "We have data till - \t2023-10-23 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-25 00:00:00.\n",
      "We have data till - \t2023-10-24 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-26 00:00:00.\n",
      "We have data till - \t2023-10-25 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-27 00:00:00.\n",
      "We have data till - \t2023-10-26 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-30 00:00:00.\n",
      "We have data till - \t2023-10-27 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-10-31 00:00:00.\n",
      "We have data till - \t2023-10-30 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-11-01 00:00:00.\n",
      "We have data till - \t2023-10-31 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-11-02 00:00:00.\n",
      "We have data till - \t2023-11-01 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-11-03 00:00:00.\n",
      "We have data till - \t2023-11-02 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-11-06 00:00:00.\n",
      "We have data till - \t2023-11-03 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-11-07 00:00:00.\n",
      "We have data till - \t2023-11-06 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-11-08 00:00:00.\n",
      "We have data till - \t2023-11-07 00:00:00.\n",
      "\n",
      "Pricing asset on - \t\t2023-11-09 00:00:00.\n",
      "We have data till - \t2023-11-08 00:00:00.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validating the rolling window boundaries\n",
    "for x, y in zip(simulation_dates, backtest_windows_with_dates):\n",
    "    print(f\"Pricing asset on - \\t\\t{x}.\")\n",
    "    print(f\"We have data till - \\t{y.index[-1]}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Interpolating the Interest Rate Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maturities = np.array([1/12, 2/12, 3/12, 4/12, 6/12, 1, 2, 3, 5, 7, 10, 20, 30])\n",
    "interest_rates.columns = maturities\n",
    "\n",
    "# The 4 month interest rate is a bit sparse\n",
    "interest_rates = interest_rates.dropna(how='any', axis=1)\n",
    "maturities = interest_rates.columns.to_numpy()\n",
    "interest_rates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate not found for date 2023-09-04 00:00:00, using the rate from the previous date.\n",
      "Rate not found for date 2023-10-09 00:00:00, using the rate from the previous date.\n"
     ]
    }
   ],
   "source": [
    "curves = []\n",
    "for date in simulation_dates:\n",
    "    try:\n",
    "        interest_rate = interest_rates.loc[date].to_numpy()\n",
    "        curve_fit, status = calibrate_ns_ols(maturities, interest_rate)\n",
    "        curves.append(curve_fit)\n",
    "\n",
    "    except KeyError:\n",
    "        # Handle the case where the rate is not found\n",
    "        print(f\"Rate not found for date {date}, using the rate from the previous date.\")\n",
    "        previous_date = interest_rates.index[interest_rates.index <= date].max()\n",
    "        corrected_rate = interest_rates.loc[previous_date].to_numpy()\n",
    "        curve_fit, status = calibrate_ns_ols(maturities, corrected_rate)\n",
    "        curves.append(curve_fit)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for date {date}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for computing Historical Volatility\n",
    "def get_lognormal_statistics(prices, delta_t):\n",
    "    log_data = np.log(prices)\n",
    "    log_returns = log_data[1:] - log_data[:-1]\n",
    "    mu = np.mean(log_returns) / delta_t\n",
    "    sigma = np.std(log_returns, ddof=1) / np.sqrt(delta_t)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for querying the annual Implied Volatility rate\n",
    "def get_implied_volatility_rate(date):\n",
    "    # We only collected the rates relavant for our timeframe\n",
    "    assert date > pd.to_datetime('2022-07-19') and date <= pd.to_datetime('2023-11-09')\n",
    "\n",
    "    try:\n",
    "        # Get the rate for the previous date (if we're predicting for tomorrow, we only have data up till yesterday)\n",
    "        previous_entry = implied_volatility_rates.loc[:date].iloc[-1]\n",
    "        implied_volatility = previous_entry['value']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for date {date}: {e}\")\n",
    "\n",
    "    return implied_volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dividend_rate(date):\n",
    "    # We only collected the rates relavant for our timeframe\n",
    "    assert date > pd.to_datetime('2022-06-17')\n",
    "\n",
    "    # Find the relavant quarter and return the dividend rate\n",
    "    for quarter_date in dividend_rates.index:\n",
    "        if date >= quarter_date:\n",
    "            return dividend_rates.loc[quarter_date, 'dividends']\n",
    "\n",
    "    print(\"Returning last rate!\")\n",
    "    return dividend_rates.loc[quarter_date, 'dividend_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.52 GiB for an array with shape (67, 20000, 753) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Coding\\MH4518\\simulations\\implied_volatility.ipynb Cell 33\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Coding/MH4518/simulations/implied_volatility.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Generating a common random variable/common randomness matrix\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Coding/MH4518/simulations/implied_volatility.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m Z_matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mnormal(\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m, size\u001b[39m=\u001b[39;49m(\u001b[39mlen\u001b[39;49m(simulation_dates), num_sim, num_periods))\n",
      "File \u001b[1;32mmtrand.pyx:1540\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.normal\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_common.pyx:636\u001b[0m, in \u001b[0;36mnumpy.random._common.cont\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.52 GiB for an array with shape (67, 20000, 753) and data type float64"
     ]
    }
   ],
   "source": [
    "# Generating a common random variable/common randomness matrix\n",
    "Z_matrix = np.random.normal(0, 1, size=(len(simulation_dates), num_sim, num_periods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4 Running the Simulations (aka The Exciting Part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.1 GBM with Dividends Adjustment\n",
    "\n",
    "This will be our baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM with Dividends without Variance Reduction\n",
    "GBM_Div_expected_values = []\n",
    "\n",
    "for date, prices in zip(simulation_dates, backtest_windows):\n",
    "  # Convert date to index (so we can lookup prices and interest rate curves)\n",
    "  date_index = simulation_dates.get_loc(date)\n",
    "\n",
    "  # Estimate r\n",
    "  delta = len(product_lifetime[date:])\n",
    "  tau = delta / 252    # time diff in years\n",
    "  curve_fit = curves[date_index]\n",
    "  r_yearly = curve_fit(tau) / 100    # yearly (interpolated) interest rate\n",
    "\n",
    "  # Calulcate mu and sigma (we discard mu)\n",
    "  _, sigma_daily = get_lognormal_statistics(prices, delta_t)    # sigma is daily variance\n",
    "\n",
    "  # IMPORTANT: Adjust the interest rate based on dividends\n",
    "  r_adjusted_yearly = r_yearly - get_dividend_rate(date) / 100\n",
    "  r_adjusted_daily = r_adjusted_yearly / 252\n",
    "\n",
    "  # Simulate prices, calculate payoff and expected value\n",
    "  simulated_prices = simulate_GBM(num_sim, prices[-1], r_adjusted_daily, sigma_daily, delta_t, tau, Z=Z_matrix[date_index])\n",
    "  payoffs = np.exp(-r_adjusted_yearly*tau)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=simulated_prices)\n",
    "  expected_value = np.mean(payoffs)\n",
    "  \n",
    "  GBM_Div_expected_values.append(expected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.2 GBM with Implied Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM with Implied Volatility without Variance Reduction\n",
    "GBM_Vol_expected_values = []\n",
    "\n",
    "for date, prices in zip(simulation_dates, backtest_windows):\n",
    "  # Convert date to index (so we can lookup prices and interest rate curves)\n",
    "  date_index = simulation_dates.get_loc(date)\n",
    "\n",
    "  # Estimate r\n",
    "  delta = len(product_lifetime[date:])\n",
    "  tau = delta / 252    # time diff in years\n",
    "  curve_fit = curves[date_index]\n",
    "  r_yearly = curve_fit(tau) / 100    # yearly (interpolated) interest rate\n",
    "\n",
    "  # Set sigma to the daily implied volatility rate\n",
    "  sigma_yearly = get_implied_volatility_rate(date) / 100\n",
    "  sigma_daily = sigma_yearly / (252**(1/2))\n",
    "\n",
    "  # We need the daily rate for the simulations\n",
    "  r_daily = r_yearly / 252\n",
    "\n",
    "  # Simulate prices, calculate payoff and expected value\n",
    "  simulated_prices = simulate_GBM(num_sim, prices[-1], r_daily, sigma_daily, delta_t, tau, Z=Z_matrix[date_index])\n",
    "  payoffs = np.exp(-r_yearly*tau)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=simulated_prices)\n",
    "  expected_value = np.mean(payoffs)\n",
    "\n",
    "  GBM_Vol_expected_values.append(expected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.3 Variance Reduction Techniques\n",
    "\n",
    "We tried, \n",
    "\n",
    "<ol> \n",
    "<li> Antithetic Variates\n",
    "<li> Control Variates\n",
    "<li> Empirical Martingale Simulation\n",
    "</ol>\n",
    "\n",
    "<br>\n",
    "NOTE: All of these use were applied on the Implied Volatility Model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM with Implied Volatility and Dividends and Antithetic Variance Reduction\n",
    "GBM_Vol_AV_expected_values = []\n",
    "\n",
    "for date, prices in zip(simulation_dates, backtest_windows):\n",
    "  # Convert date to index (so we can lookup prices and interest rate curves)\n",
    "  date_index = simulation_dates.get_loc(date)\n",
    "\n",
    "  # Estimate r\n",
    "  delta = len(product_lifetime[date:])\n",
    "  tau = delta / 252\n",
    "  curve_fit = curves[date_index]\n",
    "  r_yearly = curve_fit(tau) / 100\n",
    "\n",
    "  # Set sigma to the daily implied volatility rate\n",
    "  sigma_yearly = get_implied_volatility_rate(date) / 100\n",
    "  sigma_daily = sigma_yearly / (252**(1/2))\n",
    "\n",
    "  # We need the daily rate for the simulations\n",
    "  r_daily = r_yearly / 252\n",
    "  \n",
    "  # Simulate prices, calculate payoff and expected value\n",
    "  simulated_prices = simulate_GBM_AV(int(num_sim/2), prices[-1], r_daily, sigma_daily, delta_t, tau, Z=Z_matrix[date_index])\n",
    "  payoffs = np.exp(-r_yearly*tau)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=simulated_prices)\n",
    "  expected_value = np.mean(payoffs)\n",
    "  \n",
    "  GBM_Vol_AV_expected_values.append(expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM with Implied Volatility and Dividends and EMS Variance Reduction\n",
    "GBM_Vol_EMS_expected_values = []\n",
    "\n",
    "for date, prices in zip(simulation_dates, backtest_windows):\n",
    "  # Convert date to index (so we can lookup prices and interest rate curves)\n",
    "  date_index = simulation_dates.get_loc(date)\n",
    "\n",
    "  # Estimate r\n",
    "  delta = len(product_lifetime[date:])\n",
    "  tau = delta / 252\n",
    "  curve_fit = curves[date_index]\n",
    "  r_yearly = curve_fit(tau) / 100\n",
    "\n",
    "  # Set sigma to the daily implied volatility rate\n",
    "  sigma_yearly = get_implied_volatility_rate(date) / 100\n",
    "  sigma_daily = sigma_yearly / (252**(1/2))\n",
    "\n",
    "  # We need the daily rate for the simulations\n",
    "  r_daily = r_yearly / 252\n",
    "\n",
    "  # Simulate prices, calculate payoff and expected value\n",
    "  simulated_prices = simulate_GBM_EMS(num_sim, prices[-1], r_daily, sigma_daily, delta_t, tau, Z=Z_matrix[date_index])\n",
    "  payoffs = np.exp(-r_yearly*tau)*np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=simulated_prices)\n",
    "  expected_value = np.mean(payoffs)\n",
    "  \n",
    "  GBM_Vol_EMS_expected_values.append(expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBM with Implied Volatility and Dividends and Control Variate Variance Reduction\n",
    "GBM_Vol_CV_expected_values = []\n",
    "\n",
    "for date, prices in zip(simulation_dates, backtest_windows):\n",
    "  # Convert date to index (so we can lookup prices and interest rate curves)\n",
    "  date_index = simulation_dates.get_loc(date)\n",
    "\n",
    "  # Estimate r\n",
    "  delta = len(product_lifetime[date:])\n",
    "  tau = delta / 252\n",
    "  curve_fit = curves[date_index]\n",
    "  r_yearly = curve_fit(tau) / 100\n",
    "\n",
    "  # Set sigma to the daily implied volatility rate\n",
    "  sigma_yearly = get_implied_volatility_rate(date) / 100\n",
    "  sigma_daily = sigma_yearly / (252**(1/2))\n",
    "\n",
    "  # We need the daily rate for the simulations\n",
    "  r_daily = r_yearly / 252\n",
    "\n",
    "  # We need to sample another Z, independently, for simulating the initial pilot prices\n",
    "  Z_pilot = np.random.normal(0, 1, size=(num_sim, num_periods))\n",
    "  Z_new = Z_matrix[date_index]\n",
    "  assert Z_pilot.shape == Z_new.shape\n",
    "\n",
    "  # Simulate payoff and expected value\n",
    "  payoffs = simulate_GBM_CV(num_sim, prices[-1], r_daily, sigma_daily, delta_t, tau, Z_pilot=Z_pilot, Z_new=Z_new)\n",
    "  expected_value = np.mean(payoffs)\n",
    "  \n",
    "  GBM_Vol_CV_expected_values.append(expected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.1 Plotting the Results (aka The Moment of Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_reults = pd.DataFrame(index=simulation_dates)\n",
    "product_prices = product_prices[product_prices.index >= start_date]\n",
    "assert len(product_prices) == len(simulation_reults)\n",
    "\n",
    "# Gather data into a single dataframe\n",
    "simulation_reults['Actual'] = product_prices[\"value\"]\n",
    "simulation_reults['GBM_Div'] = GBM_Div_expected_values\n",
    "simulation_reults['Implied_Vol'] = GBM_Vol_expected_values\n",
    "simulation_reults['Implied_Vol_AV'] = GBM_Vol_AV_expected_values\n",
    "simulation_reults['Implied_Vol_EMS'] = GBM_Vol_EMS_expected_values\n",
    "simulation_reults['Implied_Vol_CV'] = GBM_Vol_CV_expected_values\n",
    "\n",
    "simulation_reults.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "simulation_reults.to_csv(os.path.join(SAVE_DIR, \"Implied_Volatility_Prices.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "plt.title('Backtesting GBM and Implied Volatility', fontdict={\"fontsize\":18})\n",
    "\n",
    "simulation_reults['Actual'].plot(legend=True)\n",
    "simulation_reults['GBM_Div'].plot(legend=True, style=\"--\")\n",
    "simulation_reults['Implied_Vol'].plot(legend=True, style=\"--\")\n",
    "\n",
    "plt.xlabel('Market Days')\n",
    "plt.ylabel('Derivative Price in USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "plt.title('Variance Reduction on the Implied Volatility Model', fontdict={\"fontsize\":18})\n",
    "\n",
    "simulation_reults['Actual'].plot(legend=True)\n",
    "simulation_reults['Implied_Vol'].plot(legend=True, style=\"--\")\n",
    "simulation_reults['Implied_Vol_AV'].plot(legend=True, style=\"--\")\n",
    "simulation_reults['Implied_Vol_EMS'].plot(legend=True, style=\"--\")\n",
    "simulation_reults['Implied_Vol_CV'].plot(legend=True, style=\"--\")\n",
    "\n",
    "plt.xlabel('Market Days')\n",
    "plt.ylabel('Derivative Price in USD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.2 Computing the Prediction Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_abs_error=mean_absolute_error(simulation_reults['Actual'].to_list(),simulation_reults['GBM_Div'].to_list())\n",
    "mean_sq_error=mean_squared_error(simulation_reults['Actual'].to_list(),simulation_reults['GBM_Div'].to_list())\n",
    "print(f'Mean Absolute Error for GBM with div:\\t\\t{mean_abs_error:.4f}')\n",
    "print(f'Mean Squared Error for GBM with div:\\t\\t{mean_sq_error:.4f}\\n')\n",
    "\n",
    "mean_abs_error=mean_absolute_error(simulation_reults['Actual'].to_list(),simulation_reults['Implied_Vol'].to_list())\n",
    "mean_sq_error=mean_squared_error(simulation_reults['Actual'].to_list(),simulation_reults['Implied_Vol'].to_list())\n",
    "print(f'Mean Absolute Error for Implied Vol:\\t{mean_abs_error:.4f}')\n",
    "print(f'Mean Squared Error for Implied Vol:\\t{mean_sq_error:.4f}\\n')\n",
    "\n",
    "mean_abs_error=mean_absolute_error(simulation_reults['Actual'].to_list(),simulation_reults['Implied_Vol_AV'].to_list())\n",
    "mean_sq_error=mean_squared_error(simulation_reults['Actual'].to_list(),simulation_reults['Implied_Vol_AV'].to_list())\n",
    "print(f'Mean Absolute Error for Implied Vol with AV:\\t{mean_abs_error:.4f}')\n",
    "print(f'Mean Squared Error for Implied Vol with AV:\\t{mean_sq_error:.4f}\\n')\n",
    "\n",
    "mean_abs_error=mean_absolute_error(simulation_reults['Actual'].to_list(),simulation_reults['Implied_Vol_EMS'].to_list())\n",
    "mean_sq_error=mean_squared_error(simulation_reults['Actual'].to_list(),simulation_reults['Implied_Vol_EMS'].to_list())\n",
    "print(f'Mean Absolute Error for Implied Vol with EMS:\\t{mean_abs_error:.4f}')\n",
    "print(f'Mean Squared Error for Implied Vol with EMS:\\t{mean_sq_error:.4f}\\n')   \n",
    "\n",
    "mean_abs_error=mean_absolute_error(simulation_reults['Actual'].to_list(),simulation_reults['Implied_Vol_CV'].to_list())\n",
    "mean_sq_error=mean_squared_error(simulation_reults['Actual'].to_list(),simulation_reults['Implied_Vol_CV'].to_list())\n",
    "print(f'Mean Absolute Error for Implied Vol with CV:\\t{mean_abs_error:.4f}')\n",
    "print(f'Mean Squared Error for Implied Vol with CV:\\t{mean_sq_error:.4f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Estimating Sensitivities\n",
    "\n",
    "The simulation results from the three scenarios; S, S+h, and S-h, are used to estimate delta and gamma for each time point by Finite-difference Method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def simulate_GBM_finite_difference(num_sim, S_0, r, sigma, delta_t, T, Z, h):\n",
    "  # Initializations\n",
    "  v = r - 0.5*(sigma**2)\n",
    "  num_periods = int(T/delta_t)\n",
    "\n",
    "  # Generate S+h and S-h matrices too\n",
    "  S_matrix = np.full(shape=(num_sim, num_periods + 1), fill_value = S_0, dtype=np.float64)\n",
    "  S_plus_h_matrix = np.full(shape=(num_sim, num_periods + 1), fill_value = S_0 + h, dtype=np.float64)\n",
    "  S_minus_h_matrix = np.full(shape=(num_sim, num_periods + 1), fill_value = S_0 - h, dtype=np.float64)\n",
    "\n",
    "  # We are using the form derived by Ito's lemma \n",
    "  for i in range(num_sim):\n",
    "    for j in range(1, num_periods + 1):\n",
    "      log_diff = v*delta_t + (sigma*np.sqrt(delta_t) * Z[i][j-1])\n",
    "      S_matrix[i][j] = S_matrix[i][j-1]*np.exp(log_diff)\n",
    "      S_plus_h_matrix[i][j] = S_plus_h_matrix[i][j-1]*np.exp(log_diff)\n",
    "      S_minus_h_matrix[i][j] = S_minus_h_matrix[i][j-1]*np.exp(log_diff)\n",
    "\n",
    "  return S_matrix, S_plus_h_matrix, S_minus_h_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating Delta with Finite-difference method\n",
    "GBM_Vol_deltas = []\n",
    "GBM_Vol_gammas = []\n",
    "\n",
    "for date, prices in zip(simulation_dates, backtest_windows):\n",
    "  # Convert date to index (so we can lookup prices and interest rate curves)\n",
    "  date_index = simulation_dates.get_loc(date)\n",
    "\n",
    "  # Estimate r\n",
    "  delta = len(product_lifetime[date:])\n",
    "  tau = delta / 252\n",
    "  curve_fit = curves[date_index]\n",
    "  r_yearly = curve_fit(tau) / 100\n",
    "\n",
    "  # Set sigma to the daily implied volatility rate\n",
    "  sigma_yearly = get_implied_volatility_rate(date) / 100\n",
    "  sigma_daily = sigma_yearly / (252**(1/2))\n",
    "\n",
    "  # We need the daily rate for the simulations\n",
    "  r_daily = r_yearly / 252\n",
    "\n",
    "  # CHECK: Set h (0.005 worked well)\n",
    "  h = 0.005\n",
    "  #h = prices[-1] * 0.01\n",
    "\n",
    "  # Simulate prices and base payoffs\n",
    "  simulated_prices, simulated_prices_plus_h, simulated_prices_minus_h = simulate_GBM_finite_difference(num_sim, prices[-1], r_daily, sigma_daily, delta_t, tau, Z=Z_matrix[date_index], h=h)\n",
    "  payoffs = np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=simulated_prices)\n",
    "  payoffs_plus_h = np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=simulated_prices_plus_h)\n",
    "  payoffs_minus_h = np.apply_along_axis(func1d=calculate_payoff, axis=1, arr=simulated_prices_minus_h)\n",
    "\n",
    "  # Caclulate and collect expected values\n",
    "  expected_value = np.exp(-r_yearly*tau) * np.mean(payoffs)\n",
    "  expected_value_plus_h = np.exp(-r_yearly*tau) * np.mean(payoffs_plus_h)\n",
    "  expected_value_minus_h = np.exp(-r_yearly*tau) * np.mean(payoffs_minus_h)\n",
    "\n",
    "  # Compute Delta and Gamma (using FDM)\n",
    "  delta = (expected_value_plus_h - expected_value_minus_h)/(2*h)\n",
    "  gamma = (expected_value_plus_h - 2*expected_value + expected_value_minus_h)/(h**2)\n",
    "\n",
    "  GBM_Vol_deltas.append(delta)\n",
    "  GBM_Vol_gammas.append(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for results\n",
    "greeks_results = pd.DataFrame(index=simulation_dates)\n",
    "greeks_results['Delta'] = GBM_Vol_deltas\n",
    "greeks_results['Gamma'] = GBM_Vol_gammas\n",
    "\n",
    "print(f\"Average Delta: {np.mean(GBM_Vol_deltas):.4f}\")\n",
    "print(f\"Average Gamma: {np.mean(GBM_Vol_gammas):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Delta\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(greeks_results.index, greeks_results['Delta'], label='Delta', color='tab:orange', linestyle='--')\n",
    "plt.title('Delta', fontsize=16)\n",
    "plt.xlabel('Market Days', fontsize=14)\n",
    "plt.ylabel('Delta Value in USD', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot Gamma\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(greeks_results.index, greeks_results['Gamma'], label='Gamma', color='tab:blue', linestyle='--')\n",
    "plt.title('Gamma', fontsize=16)\n",
    "plt.xlabel('Market Days', fontsize=14)\n",
    "plt.ylabel('Gamma Value in USD', fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "greeks_results.to_csv(os.path.join(SAVE_DIR, \"Implied_Volatility__Greeks_0.005.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's about it for the Implied Volatility model. Feel free to explore the other notebooks in `/models` for more compliated models.\n",
    "\n",
    "#### Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mh4518",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
